<img src="http://imgur.com/1ZcRyrc.png" style="float: left; margin: 20px; height: 55px">

# Introduction to Classification

Unit 3: Lesson 12

### Part 1: Introduction to Classification & KNN

### Part 2: Logistic Regression

## Materials We Provide

| Topic    | Description         | Link                                 |
| -------- | ------------------- | ------------------------------------ |
| Lesson   | KNN Classification  | [Here](01_classification_knn.ipynb)  |
|          | Logistic Regression | [Here](02_logistic_regression.ipynb) |
| Practice | Practice            | [Here](practice/)                    |



## Learning Objectives

After this lesson, students will be able to:

- **Utilize** the KNN model on the iris data set.
- Implement scikit-learn's KNN model.
- Assess the fit of a KNN Model using scikit-learn.

- **Recall** how to perform linear regression in scikit-learn.
- **Demonstrate** why logistic regression is a better alternative for classification than linear regression.
- **Understand** the concepts of probability, odds, e, log, and log-odds in relation to machine learning.
- **Explain** how logistic regression works.
- **Interpret** logistic regression coefficients.
- **Use** logistic regression with categorical features.
- **Compare** logistic regression with other models.
- **Utilize** different metrics for evaluating classifier models.
- **Construct** a confusion matrix based on predicted classes.

---

## Student Requirements

Before this lesson(s), students should already be able to:

- Load in and perform basic analysis and manipulation on data in Pandas 
- Build and interpret a linear regression model
- Explain the basics of probability
- Distinguish between continuous and categorical variables
- Understand the bias-variance tradeoff and use confusion matrices to tune this balance

----

## Lesson Outline

- Overview of the Iris Data Set
  - Terminology
- Exercise: "Human Learning" With Iris Data
- Human Learning on the Iris Data Set
- K-Nearest Neighbors (KNN) Classification
  - Using the Train/Test Split Procedure (K=1)
- Tuning a KNN Model
  - What Happens If We View the Accuracy of our Training Data?
  - Training Error Versus Testing Error
- Standardizing Features
  - Use StandardScaler to Standardize our Data.
- Comparing KNN With Other Models
- Predicting a Categorical Response
- Using logistic regression for classification
- Probability, odds ratio, e, log, and log-odds
  - Understanding e and the natural logarithm
  - The log-odds ratio
- What is Logistic Regression?
- Interpreting Logistic Regression Coefficients
- Using Logistic Regression with Categorical Features
- Comparing Logistic Regression to Other Models
- Advanced Classification Metrics
  - Accuracy, True Positive Rate, and False Negative Rate
  - The accuracy paradox
- Lesson Review

---

## Additional Resources

For more information on this topic, check out the following resources:

- [Data School: Machine Learning With KNN](http://blog.kaggle.com/2015/04/30/scikit-learn-video-4-model-training-and-prediction-with-k-nearest-neighbors/)
- [KNN: Dangerously Simple](https://mathbabe.org/2013/04/04/k-nearest-neighbors-dangerously-simple/)
- [KNN From Scratch](http://machinelearningmastery.com/tutorial-to-implement-k-nearest-neighbors-in-python-from-scratch/)
- [Detailed Intro to KNN](https://saravananthirumuruganathan.wordpress.com/2010/05/17/a-detailed-introduction-to-k-nearest-neighbor-knn-algorithm/)
- [Stanford's Machine Learning Course: KNN](http://cs231n.github.io/classification/#nn)

- [Sklearn Logistic Regression Documentation](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwj-ytGQkZjVAhWHej4KHaOcCnYQFggzMAE&url=http%3A%2F%2Fscikit-learn.org%2Fstable%2Fmodules%2Fgenerated%2Fsklearn.linear_model.LogisticRegression.html&usg=AFQjCNGpSyUzpbaClG8IQEPJmB63CQZlrg)
- [Data School: Logistic Regression In-Depth](http://www.dataschool.io/guide-to-logistic-regression/)
- [Logistic Regression for Machine Learning](http://machinelearningmastery.com/logistic-regression-for-machine-learning/)
- [Video: Andrew Ng on Logistic Regression](https://www.youtube.com/watch?v=LLx4diIP83I)